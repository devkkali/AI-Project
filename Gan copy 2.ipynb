{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "37mwujP4zIcl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "RSSizP_CzJF_",
        "outputId": "d752a01f-08d5-443c-dd53-67b39ef1d16c"
      },
      "outputs": [],
      "source": [
        "path = 'dataset/'\n",
        "conversations_file = 'movie_conversations.txt'\n",
        "lines_file = 'movie_lines.txt'\n",
        "\n",
        "\n",
        "# Specify the parent directory where you want to save the models\n",
        "parent_dir = \"model/gan_model\"\n",
        "\n",
        "# Get input from the user for the number\n",
        "number = input(\"Enter the number: \")\n",
        "\n",
        "# Create the folder name by concatenating \"model_\" with the number\n",
        "folder_name = f\"model_{number}\"\n",
        "\n",
        "# Create the full path for the new folder\n",
        "save_dir = os.path.join(parent_dir, folder_name)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NcR7LponzbgX"
      },
      "outputs": [],
      "source": [
        "subset_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VHZ4pHwW45Gb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Totla conversation_pairs 83097\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the dataset\n",
        "def load_dataset():\n",
        "    conversations = open(path+conversations_file, 'r', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "    lines = open(path+lines_file, 'r', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "\n",
        "    id2line = {}\n",
        "    for line in lines:\n",
        "        parts = line.split(' +++$+++ ')\n",
        "        if len(parts) == 5:\n",
        "            id2line[parts[0]] = parts[4]\n",
        "\n",
        "    # print(id2line)\n",
        "\n",
        "    # if subset_size is not None:\n",
        "      # lines = lines(subset_size)\n",
        "\n",
        "\n",
        "    conversation_pairs = []\n",
        "    for conversation in conversations:\n",
        "        parts = conversation.split(' +++$+++ ')\n",
        "        if len(parts) == 4:\n",
        "            line_ids = parts[3][1:-1].replace(\"'\", \"\").replace(\" \", \"\").split(\",\")\n",
        "            line_ids = line_ids[1:3]\n",
        "            pair = [id2line[line_id] for line_id in line_ids]\n",
        "            conversation_pairs.append(pair)\n",
        "\n",
        "    print('Totla conversation_pairs',len(conversation_pairs))\n",
        "    return conversation_pairs[:subset_size]\n",
        "    # return conversation_pairs\n",
        "\n",
        "conversation_pairs = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(conversation_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-D6btG88OkBe"
      },
      "outputs": [],
      "source": [
        "# Prepare input and target sequences\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "for pair in conversation_pairs:\n",
        "    for i in range(len(pair) - 1):\n",
        "        input_texts.append(pair[i])\n",
        "        target_texts.append(pair[i + 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sSFcQyV4PAVt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(conversation_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TXqEpsaJOuM5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
            "Well, I thought we'd start with pronunciation, if that's okay with you.\n"
          ]
        }
      ],
      "source": [
        "print(input_texts[0])\n",
        "print(target_texts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4eU4Jo83lowp"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(input_texts + target_texts)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VS06x1aGluDq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "177"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XJYw-yywmkxg"
      },
      "outputs": [],
      "source": [
        "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
        "target_sequences = tokenizer.texts_to_sequences(target_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DeFm8RrumuoO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(input_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZbdRQEjrml2P"
      },
      "outputs": [],
      "source": [
        "# Pad sequences\n",
        "max_sequence_length = max(max(len(seq) for seq in input_sequences), max(len(seq) for seq in target_sequences))\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
        "target_sequences = pad_sequences(target_sequences, maxlen=max_sequence_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cVM7EJE_m5fq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(input_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T3bpwOsUnLTj"
      },
      "outputs": [],
      "source": [
        "# Prepare the training data\n",
        "encoder_input_data = input_sequences\n",
        "decoder_input_data = target_sequences[:, :-1]\n",
        "decoder_target_data = target_sequences[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PqTjJ3Fkn5NT"
      },
      "outputs": [],
      "source": [
        "# Define the Generator network\n",
        "latent_dim = 256\n",
        "\n",
        "generator_inputs = keras.Input(shape=(max_sequence_length-1,))\n",
        "generator_embedding = keras.layers.Embedding(vocab_size, latent_dim)(generator_inputs)\n",
        "\n",
        "# Add the first LSTM layer\n",
        "generator_lstm_1 = keras.layers.LSTM(10, return_sequences=True)(generator_embedding)\n",
        "\n",
        "# Add the second LSTM layer\n",
        "generator_lstm_2 = keras.layers.LSTM(10, return_sequences=True)(generator_lstm_1)\n",
        "\n",
        "# Output layer (TimeDistributed Dense)\n",
        "generator_outputs = keras.layers.TimeDistributed(keras.layers.Dense(vocab_size, activation='softmax'))(generator_lstm_2)\n",
        "\n",
        "# Create the Generator model\n",
        "generator_model = keras.Model(generator_inputs, generator_outputs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7Hq9r8WHqiSd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 43)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 43, 256)           45312     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 43, 10)            10680     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 43, 10)            840       \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 43, 177)          1947      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,779\n",
            "Trainable params: 58,779\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Generator Output Shape: (None, 43, 177)\n"
          ]
        }
      ],
      "source": [
        "print(generator_model.summary())\n",
        "output_shape = generator_model.output_shape\n",
        "print(\"Generator Output Shape:\", output_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VnB7cd8QoAO6"
      },
      "outputs": [],
      "source": [
        "# Define the Discriminator network\n",
        "discriminator_inputs = keras.Input(shape=(max_sequence_length-1, vocab_size))\n",
        "\n",
        "# Add the first LSTM layer\n",
        "discriminator_lstm_1 = keras.layers.LSTM(10, return_sequences=True)(discriminator_inputs)\n",
        "\n",
        "# Add the second LSTM layer\n",
        "discriminator_lstm_2 = keras.layers.LSTM(10)(discriminator_lstm_1)\n",
        "\n",
        "# Output layer (Dense)\n",
        "discriminator_outputs = keras.layers.Dense(1, activation='sigmoid')(discriminator_lstm_2)\n",
        "\n",
        "# Create the Discriminator model\n",
        "discriminator_model = keras.Model(discriminator_inputs, discriminator_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6zZxcfVDq3rA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 43, 177)]         0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 43, 10)            7520      \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 10)                840       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,371\n",
            "Trainable params: 8,371\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Discriminator Input Shape: (None, 43, 177)\n"
          ]
        }
      ],
      "source": [
        "print(discriminator_model.summary())\n",
        "input_shape = discriminator_model.input_shape\n",
        "print(\"Discriminator Input Shape:\", input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-E-JaFDPFoYJ"
      },
      "outputs": [],
      "source": [
        "# Define the GAN model\n",
        "gan_inputs = keras.Input(shape=(max_sequence_length-1,))\n",
        "generated_sequences = generator_model(gan_inputs)\n",
        "gan_outputs = discriminator_model(generated_sequences)\n",
        "gan_model = keras.Model(gan_inputs, gan_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VpB-b4gGHdUh"
      },
      "outputs": [],
      "source": [
        "# Compile the Discriminator model\n",
        "discriminator_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Compile the GAN model\n",
        "gan_model.compile(loss='binary_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tn2UpVNVun1W"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "batch_size = 64\n",
        "epochs = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mxOo9CmHi3Hy"
      },
      "outputs": [],
      "source": [
        "real_data=encoder_input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e0jjDYlK3r_O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 615ms/step\n",
            "Epoch 1: Discriminator Loss=0.6952099204063416, GAN Loss=0.690049946308136\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 2: Discriminator Loss=0.6920076608657837, GAN Loss=0.6861016154289246\n",
            "1/1 [==============================] - 1s 606ms/step\n",
            "Epoch 3: Discriminator Loss=0.6882973909378052, GAN Loss=0.682294487953186\n",
            "1/1 [==============================] - 1s 587ms/step\n",
            "Epoch 4: Discriminator Loss=0.6863009333610535, GAN Loss=0.6787853837013245\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000210BC9D84C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 5: Discriminator Loss=0.6851466298103333, GAN Loss=0.675617516040802\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000210BC9D97E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 6: Discriminator Loss=0.6842702627182007, GAN Loss=0.6727896928787231\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 7: Discriminator Loss=0.6836397051811218, GAN Loss=0.6702320575714111\n",
            "1/1 [==============================] - 1s 738ms/step\n",
            "Epoch 8: Discriminator Loss=0.6824958324432373, GAN Loss=0.6678779125213623\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 9: Discriminator Loss=0.6817927956581116, GAN Loss=0.6657150983810425\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 10: Discriminator Loss=0.6810476183891296, GAN Loss=0.6637136936187744\n",
            "1/1 [==============================] - 1s 613ms/step\n",
            "Epoch 11: Discriminator Loss=0.680253267288208, GAN Loss=0.6618409156799316\n",
            "1/1 [==============================] - 1s 563ms/step\n",
            "Epoch 12: Discriminator Loss=0.6794124245643616, GAN Loss=0.6600591540336609\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 13: Discriminator Loss=0.6785218119621277, GAN Loss=0.6583330631256104\n",
            "1/1 [==============================] - 1s 592ms/step\n",
            "Epoch 14: Discriminator Loss=0.6775650978088379, GAN Loss=0.656632661819458\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 15: Discriminator Loss=0.6761705279350281, GAN Loss=0.6549256443977356\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 16: Discriminator Loss=0.6747950911521912, GAN Loss=0.6531867980957031\n",
            "1/1 [==============================] - 1s 561ms/step\n",
            "Epoch 17: Discriminator Loss=0.6723288297653198, GAN Loss=0.6513060927391052\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 18: Discriminator Loss=0.6707437038421631, GAN Loss=0.6492737531661987\n",
            "1/1 [==============================] - 1s 556ms/step\n",
            "Epoch 19: Discriminator Loss=0.6690361499786377, GAN Loss=0.6470504999160767\n",
            "1/1 [==============================] - 1s 774ms/step\n",
            "Epoch 20: Discriminator Loss=0.6671714186668396, GAN Loss=0.6446175575256348\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "Epoch 21: Discriminator Loss=0.6651176810264587, GAN Loss=0.6419181227684021\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 22: Discriminator Loss=0.662843644618988, GAN Loss=0.6389164924621582\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "Epoch 23: Discriminator Loss=0.6603063941001892, GAN Loss=0.6355339288711548\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 24: Discriminator Loss=0.6574254035949707, GAN Loss=0.6316882371902466\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 25: Discriminator Loss=0.6541328430175781, GAN Loss=0.6273002028465271\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 26: Discriminator Loss=0.6504097580909729, GAN Loss=0.6222292184829712\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "Epoch 27: Discriminator Loss=0.6461881399154663, GAN Loss=0.616389811038971\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 28: Discriminator Loss=0.6416160464286804, GAN Loss=0.609542965888977\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 29: Discriminator Loss=0.6369385719299316, GAN Loss=0.6014961004257202\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 30: Discriminator Loss=0.6325817108154297, GAN Loss=0.5921908617019653\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 31: Discriminator Loss=0.6291165947914124, GAN Loss=0.5816043615341187\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 32: Discriminator Loss=0.6270972490310669, GAN Loss=0.5700644850730896\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 33: Discriminator Loss=0.6267897486686707, GAN Loss=0.5578205585479736\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 34: Discriminator Loss=0.628265917301178, GAN Loss=0.5452972650527954\n",
            "1/1 [==============================] - 1s 877ms/step\n",
            "Epoch 35: Discriminator Loss=0.6313509941101074, GAN Loss=0.5326879024505615\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 36: Discriminator Loss=0.635787308216095, GAN Loss=0.5202135443687439\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 37: Discriminator Loss=0.6414467096328735, GAN Loss=0.5079964399337769\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 38: Discriminator Loss=0.6477502584457397, GAN Loss=0.4960722327232361\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 39: Discriminator Loss=0.6536951065063477, GAN Loss=0.48464131355285645\n",
            "1/1 [==============================] - 1s 557ms/step\n",
            "Epoch 40: Discriminator Loss=0.661807119846344, GAN Loss=0.47378265857696533\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 41: Discriminator Loss=0.6707704663276672, GAN Loss=0.46357887983322144\n",
            "1/1 [==============================] - 1s 635ms/step\n",
            "Epoch 42: Discriminator Loss=0.6798363327980042, GAN Loss=0.454061895608902\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 43: Discriminator Loss=0.6887449622154236, GAN Loss=0.4451959729194641\n",
            "1/1 [==============================] - 1s 605ms/step\n",
            "Epoch 44: Discriminator Loss=0.6973778605461121, GAN Loss=0.43695223331451416\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 45: Discriminator Loss=0.7054663300514221, GAN Loss=0.4292619824409485\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 46: Discriminator Loss=0.7129669189453125, GAN Loss=0.4220687448978424\n",
            "1/1 [==============================] - 1s 597ms/step\n",
            "Epoch 47: Discriminator Loss=0.7200784683227539, GAN Loss=0.41529980301856995\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 48: Discriminator Loss=0.7266120910644531, GAN Loss=0.4089377522468567\n",
            "1/1 [==============================] - 1s 560ms/step\n",
            "Epoch 49: Discriminator Loss=0.7327700257301331, GAN Loss=0.4028659462928772\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 50: Discriminator Loss=0.7384575605392456, GAN Loss=0.3970731198787689\n",
            "1/1 [==============================] - 1s 598ms/step\n",
            "Epoch 51: Discriminator Loss=0.7437595725059509, GAN Loss=0.3915407657623291\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 52: Discriminator Loss=0.7486991882324219, GAN Loss=0.386245459318161\n",
            "1/1 [==============================] - 1s 922ms/step\n",
            "Epoch 53: Discriminator Loss=0.7533435225486755, GAN Loss=0.3811492323875427\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 54: Discriminator Loss=0.7577305436134338, GAN Loss=0.3762396275997162\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 55: Discriminator Loss=0.7618239521980286, GAN Loss=0.3715174198150635\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 56: Discriminator Loss=0.7657338976860046, GAN Loss=0.3669576346874237\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 57: Discriminator Loss=0.7694228291511536, GAN Loss=0.3625434637069702\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 58: Discriminator Loss=0.7729185819625854, GAN Loss=0.3583199083805084\n",
            "1/1 [==============================] - 1s 557ms/step\n",
            "Epoch 59: Discriminator Loss=0.7762415409088135, GAN Loss=0.35419076681137085\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "Epoch 60: Discriminator Loss=0.7793659567832947, GAN Loss=0.35022789239883423\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 61: Discriminator Loss=0.7823894023895264, GAN Loss=0.34641292691230774\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 62: Discriminator Loss=0.7851928472518921, GAN Loss=0.34276312589645386\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 63: Discriminator Loss=0.7878900170326233, GAN Loss=0.3392102122306824\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 64: Discriminator Loss=0.7903977036476135, GAN Loss=0.33584511280059814\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "Epoch 65: Discriminator Loss=0.7928388714790344, GAN Loss=0.3326111435890198\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 66: Discriminator Loss=0.7951303720474243, GAN Loss=0.3295682966709137\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 67: Discriminator Loss=0.7972197532653809, GAN Loss=0.32668837904930115\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 68: Discriminator Loss=0.799191951751709, GAN Loss=0.3239666521549225\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 69: Discriminator Loss=0.8010048866271973, GAN Loss=0.32143715023994446\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 70: Discriminator Loss=0.8026176691055298, GAN Loss=0.3190574645996094\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 71: Discriminator Loss=0.8041271567344666, GAN Loss=0.31687167286872864\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 72: Discriminator Loss=0.8071670532226562, GAN Loss=0.3148350715637207\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 73: Discriminator Loss=0.8087108731269836, GAN Loss=0.3129562735557556\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 74: Discriminator Loss=0.8099040985107422, GAN Loss=0.3112352788448334\n",
            "1/1 [==============================] - 1s 952ms/step\n",
            "Epoch 75: Discriminator Loss=0.8109197616577148, GAN Loss=0.3096522390842438\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 76: Discriminator Loss=0.8118287324905396, GAN Loss=0.30824482440948486\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 77: Discriminator Loss=0.8126095533370972, GAN Loss=0.3069863021373749\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 78: Discriminator Loss=0.8132913708686829, GAN Loss=0.3058479428291321\n",
            "1/1 [==============================] - 1s 626ms/step\n",
            "Epoch 79: Discriminator Loss=0.8137866258621216, GAN Loss=0.30488210916519165\n",
            "1/1 [==============================] - 1s 604ms/step\n",
            "Epoch 80: Discriminator Loss=0.8141968250274658, GAN Loss=0.30403366684913635\n",
            "1/1 [==============================] - 1s 601ms/step\n",
            "Epoch 81: Discriminator Loss=0.8144890666007996, GAN Loss=0.30332955718040466\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 82: Discriminator Loss=0.8146929144859314, GAN Loss=0.3027346730232239\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 83: Discriminator Loss=0.8147639632225037, GAN Loss=0.3022741675376892\n",
            "1/1 [==============================] - 1s 563ms/step\n",
            "Epoch 84: Discriminator Loss=0.8147702217102051, GAN Loss=0.30190229415893555\n",
            "1/1 [==============================] - 1s 561ms/step\n",
            "Epoch 85: Discriminator Loss=0.8146607279777527, GAN Loss=0.3016701936721802\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "Epoch 86: Discriminator Loss=0.8144871592521667, GAN Loss=0.3014949560165405\n",
            "1/1 [==============================] - 1s 561ms/step\n",
            "Epoch 87: Discriminator Loss=0.8142129778862, GAN Loss=0.3014207184314728\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 88: Discriminator Loss=0.8138576745986938, GAN Loss=0.30143800377845764\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 89: Discriminator Loss=0.8134492039680481, GAN Loss=0.30152058601379395\n",
            "1/1 [==============================] - 1s 559ms/step\n",
            "Epoch 90: Discriminator Loss=0.8130203485488892, GAN Loss=0.3016713857650757\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 91: Discriminator Loss=0.8124926090240479, GAN Loss=0.30188456177711487\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 92: Discriminator Loss=0.8119535446166992, GAN Loss=0.30214622616767883\n",
            "1/1 [==============================] - 1s 560ms/step\n",
            "Epoch 93: Discriminator Loss=0.8113492727279663, GAN Loss=0.30245092511177063\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 94: Discriminator Loss=0.8107689023017883, GAN Loss=0.3027969002723694\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 95: Discriminator Loss=0.8101747632026672, GAN Loss=0.303168386220932\n",
            "1/1 [==============================] - 1s 561ms/step\n",
            "Epoch 96: Discriminator Loss=0.8110488653182983, GAN Loss=0.303541362285614\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 97: Discriminator Loss=0.810746967792511, GAN Loss=0.3039429187774658\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "Epoch 98: Discriminator Loss=0.8102481365203857, GAN Loss=0.3042944669723511\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "Epoch 99: Discriminator Loss=0.8096619248390198, GAN Loss=0.3046610951423645\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 100: Discriminator Loss=0.8091517686843872, GAN Loss=0.30499106645584106\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 101: Discriminator Loss=0.8086245656013489, GAN Loss=0.30531829595565796\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 102: Discriminator Loss=0.808128297328949, GAN Loss=0.3056151270866394\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "Epoch 103: Discriminator Loss=0.8076852560043335, GAN Loss=0.30588072538375854\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 104: Discriminator Loss=0.8072360157966614, GAN Loss=0.30612996220588684\n",
            "1/1 [==============================] - 1s 557ms/step\n",
            "Epoch 105: Discriminator Loss=0.8068264722824097, GAN Loss=0.3063396215438843\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "Epoch 106: Discriminator Loss=0.8064260482788086, GAN Loss=0.3065146803855896\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 107: Discriminator Loss=0.8061017990112305, GAN Loss=0.30665260553359985\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 108: Discriminator Loss=0.8058010339736938, GAN Loss=0.3067646622657776\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 109: Discriminator Loss=0.8054890036582947, GAN Loss=0.30683833360671997\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 110: Discriminator Loss=0.8052458763122559, GAN Loss=0.30686673521995544\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 111: Discriminator Loss=0.8049812316894531, GAN Loss=0.30687403678894043\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 112: Discriminator Loss=0.804752767086029, GAN Loss=0.306864470243454\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 113: Discriminator Loss=0.8045700192451477, GAN Loss=0.3068336248397827\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 114: Discriminator Loss=0.8044016361236572, GAN Loss=0.30677956342697144\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 115: Discriminator Loss=0.8042510151863098, GAN Loss=0.3066897392272949\n",
            "1/1 [==============================] - 1s 560ms/step\n",
            "Epoch 116: Discriminator Loss=0.8041204214096069, GAN Loss=0.30658456683158875\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 117: Discriminator Loss=0.8039953112602234, GAN Loss=0.306454062461853\n",
            "1/1 [==============================] - 1s 560ms/step\n",
            "Epoch 118: Discriminator Loss=0.8038657307624817, GAN Loss=0.30630457401275635\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 119: Discriminator Loss=0.8037077188491821, GAN Loss=0.3061700165271759\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 120: Discriminator Loss=0.8035629987716675, GAN Loss=0.3060647249221802\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 121: Discriminator Loss=0.8033733367919922, GAN Loss=0.30598771572113037\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 122: Discriminator Loss=0.803146243095398, GAN Loss=0.30592578649520874\n",
            "1/1 [==============================] - 1s 510ms/step\n",
            "Epoch 123: Discriminator Loss=0.8028786182403564, GAN Loss=0.30590951442718506\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 124: Discriminator Loss=0.8025728464126587, GAN Loss=0.3059208393096924\n",
            "1/1 [==============================] - 1s 563ms/step\n",
            "Epoch 125: Discriminator Loss=0.8022165894508362, GAN Loss=0.305963397026062\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 126: Discriminator Loss=0.8017922043800354, GAN Loss=0.30603671073913574\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 127: Discriminator Loss=0.8013443946838379, GAN Loss=0.3061463236808777\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 128: Discriminator Loss=0.8008391261100769, GAN Loss=0.30628159642219543\n",
            "1/1 [==============================] - 1s 560ms/step\n",
            "Epoch 129: Discriminator Loss=0.8003247976303101, GAN Loss=0.30643564462661743\n",
            "1/1 [==============================] - 1s 560ms/step\n",
            "Epoch 130: Discriminator Loss=0.7997397780418396, GAN Loss=0.3066219687461853\n",
            "1/1 [==============================] - 1s 559ms/step\n",
            "Epoch 131: Discriminator Loss=0.7991254329681396, GAN Loss=0.3068180978298187\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 132: Discriminator Loss=0.7984998226165771, GAN Loss=0.3070286512374878\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 133: Discriminator Loss=0.7978199124336243, GAN Loss=0.3072603940963745\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 134: Discriminator Loss=0.797119140625, GAN Loss=0.30749958753585815\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 135: Discriminator Loss=0.7964116930961609, GAN Loss=0.30774056911468506\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 136: Discriminator Loss=0.7956477403640747, GAN Loss=0.3079962134361267\n",
            "1/1 [==============================] - 1s 587ms/step\n",
            "Epoch 137: Discriminator Loss=0.7948907613754272, GAN Loss=0.30825376510620117\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 138: Discriminator Loss=0.7941051721572876, GAN Loss=0.30850252509117126\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 139: Discriminator Loss=0.7933029532432556, GAN Loss=0.30874621868133545\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 140: Discriminator Loss=0.7924837470054626, GAN Loss=0.3089835047721863\n",
            "1/1 [==============================] - 1s 601ms/step\n",
            "Epoch 141: Discriminator Loss=0.7916359305381775, GAN Loss=0.3092118501663208\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 142: Discriminator Loss=0.7907942533493042, GAN Loss=0.3094532787799835\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 143: Discriminator Loss=0.7899115681648254, GAN Loss=0.3096710443496704\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 144: Discriminator Loss=0.7889957427978516, GAN Loss=0.3098822236061096\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 145: Discriminator Loss=0.7880766987800598, GAN Loss=0.31009209156036377\n",
            "1/1 [==============================] - 1s 606ms/step\n",
            "Epoch 146: Discriminator Loss=0.787106990814209, GAN Loss=0.3103071451187134\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 147: Discriminator Loss=0.7860885858535767, GAN Loss=0.3105142116546631\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 148: Discriminator Loss=0.7850421071052551, GAN Loss=0.31073838472366333\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 149: Discriminator Loss=0.7839339375495911, GAN Loss=0.3109900653362274\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 150: Discriminator Loss=0.7827746868133545, GAN Loss=0.3112671375274658\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 151: Discriminator Loss=0.7815338969230652, GAN Loss=0.3116056025028229\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 152: Discriminator Loss=0.7802433371543884, GAN Loss=0.3120255470275879\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 153: Discriminator Loss=0.7788673639297485, GAN Loss=0.31254464387893677\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 154: Discriminator Loss=0.7774152755737305, GAN Loss=0.3131754994392395\n",
            "1/1 [==============================] - 1s 601ms/step\n",
            "Epoch 155: Discriminator Loss=0.7758683562278748, GAN Loss=0.3139665722846985\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 156: Discriminator Loss=0.7741877436637878, GAN Loss=0.31491053104400635\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 157: Discriminator Loss=0.7723516225814819, GAN Loss=0.31598737835884094\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 158: Discriminator Loss=0.7703596949577332, GAN Loss=0.3171852231025696\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 159: Discriminator Loss=0.768197238445282, GAN Loss=0.3184683918952942\n",
            "1/1 [==============================] - 1s 602ms/step\n",
            "Epoch 160: Discriminator Loss=0.7659129500389099, GAN Loss=0.31980228424072266\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 161: Discriminator Loss=0.7635229825973511, GAN Loss=0.3211531937122345\n",
            "1/1 [==============================] - 1s 593ms/step\n",
            "Epoch 162: Discriminator Loss=0.7610971331596375, GAN Loss=0.3224583566188812\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 163: Discriminator Loss=0.7587094902992249, GAN Loss=0.323703408241272\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 164: Discriminator Loss=0.7564052939414978, GAN Loss=0.3248354494571686\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 165: Discriminator Loss=0.754206657409668, GAN Loss=0.32583940029144287\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 166: Discriminator Loss=0.7521743774414062, GAN Loss=0.3266925513744354\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 167: Discriminator Loss=0.7503136396408081, GAN Loss=0.3273816704750061\n",
            "1/1 [==============================] - 1s 563ms/step\n",
            "Epoch 168: Discriminator Loss=0.7486284375190735, GAN Loss=0.327897846698761\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 169: Discriminator Loss=0.7471176981925964, GAN Loss=0.32825082540512085\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Epoch 170: Discriminator Loss=0.7457818984985352, GAN Loss=0.32846683263778687\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 171: Discriminator Loss=0.744583785533905, GAN Loss=0.3285363018512726\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 172: Discriminator Loss=0.7435311079025269, GAN Loss=0.3285093903541565\n",
            "1/1 [==============================] - 1s 561ms/step\n",
            "Epoch 173: Discriminator Loss=0.7425640821456909, GAN Loss=0.3284030258655548\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 174: Discriminator Loss=0.7416883111000061, GAN Loss=0.32824063301086426\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 175: Discriminator Loss=0.7408902645111084, GAN Loss=0.32803717255592346\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 176: Discriminator Loss=0.7401361465454102, GAN Loss=0.32783132791519165\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 177: Discriminator Loss=0.7394038438796997, GAN Loss=0.3276318311691284\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 178: Discriminator Loss=0.738673210144043, GAN Loss=0.327439546585083\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 179: Discriminator Loss=0.7379587888717651, GAN Loss=0.3272746503353119\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 180: Discriminator Loss=0.7372074723243713, GAN Loss=0.3271341323852539\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 181: Discriminator Loss=0.7364688515663147, GAN Loss=0.32702377438545227\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 182: Discriminator Loss=0.7356823682785034, GAN Loss=0.3269469439983368\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 183: Discriminator Loss=0.7348780035972595, GAN Loss=0.3269002437591553\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 184: Discriminator Loss=0.7340707182884216, GAN Loss=0.3268824815750122\n",
            "1/1 [==============================] - 1s 601ms/step\n",
            "Epoch 185: Discriminator Loss=0.7332302927970886, GAN Loss=0.32688722014427185\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 186: Discriminator Loss=0.7323868870735168, GAN Loss=0.3269161581993103\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 187: Discriminator Loss=0.7315442562103271, GAN Loss=0.3269672989845276\n",
            "1/1 [==============================] - 1s 603ms/step\n",
            "Epoch 188: Discriminator Loss=0.7306867241859436, GAN Loss=0.3270280957221985\n",
            "1/1 [==============================] - 1s 566ms/step\n",
            "Epoch 189: Discriminator Loss=0.729850709438324, GAN Loss=0.32710400223731995\n",
            "1/1 [==============================] - 1s 608ms/step\n",
            "Epoch 190: Discriminator Loss=0.7290116548538208, GAN Loss=0.3271843492984772\n",
            "1/1 [==============================] - 1s 607ms/step\n",
            "Epoch 191: Discriminator Loss=0.7281792163848877, GAN Loss=0.327281653881073\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 192: Discriminator Loss=0.7273589968681335, GAN Loss=0.32738059759140015\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 193: Discriminator Loss=0.7265569567680359, GAN Loss=0.32748788595199585\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 194: Discriminator Loss=0.7257579565048218, GAN Loss=0.32760024070739746\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 195: Discriminator Loss=0.7249776124954224, GAN Loss=0.32771411538124084\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 196: Discriminator Loss=0.7242034077644348, GAN Loss=0.3278420865535736\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 197: Discriminator Loss=0.7234439849853516, GAN Loss=0.32797446846961975\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 198: Discriminator Loss=0.7226876616477966, GAN Loss=0.3281143307685852\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 199: Discriminator Loss=0.7219557166099548, GAN Loss=0.32826101779937744\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 200: Discriminator Loss=0.7212200164794922, GAN Loss=0.3284221887588501\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 201: Discriminator Loss=0.7204987406730652, GAN Loss=0.32858842611312866\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 202: Discriminator Loss=0.7197827696800232, GAN Loss=0.32876062393188477\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "Epoch 203: Discriminator Loss=0.7190811634063721, GAN Loss=0.3289414048194885\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 204: Discriminator Loss=0.7183833718299866, GAN Loss=0.3291292190551758\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 205: Discriminator Loss=0.7177011370658875, GAN Loss=0.3293180465698242\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 206: Discriminator Loss=0.7170235514640808, GAN Loss=0.32951486110687256\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 207: Discriminator Loss=0.7163622975349426, GAN Loss=0.3297070860862732\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 208: Discriminator Loss=0.7157125473022461, GAN Loss=0.3299034833908081\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 209: Discriminator Loss=0.7150716781616211, GAN Loss=0.3300989866256714\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 210: Discriminator Loss=0.7144479155540466, GAN Loss=0.3302910327911377\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 211: Discriminator Loss=0.7138243317604065, GAN Loss=0.3304824233055115\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 212: Discriminator Loss=0.7131778001785278, GAN Loss=0.33067023754119873\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 213: Discriminator Loss=0.7126690745353699, GAN Loss=0.3308718502521515\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 214: Discriminator Loss=0.7121227979660034, GAN Loss=0.331076443195343\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 215: Discriminator Loss=0.7115508317947388, GAN Loss=0.3312884569168091\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Epoch 216: Discriminator Loss=0.710964560508728, GAN Loss=0.33149898052215576\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 217: Discriminator Loss=0.7103769183158875, GAN Loss=0.33171069622039795\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 218: Discriminator Loss=0.7097985148429871, GAN Loss=0.3319169282913208\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 219: Discriminator Loss=0.7092289328575134, GAN Loss=0.3321168124675751\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 220: Discriminator Loss=0.7086729407310486, GAN Loss=0.3323069214820862\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 221: Discriminator Loss=0.708137035369873, GAN Loss=0.3324841260910034\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 222: Discriminator Loss=0.7076181173324585, GAN Loss=0.3326541483402252\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 223: Discriminator Loss=0.707122802734375, GAN Loss=0.3328084945678711\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 224: Discriminator Loss=0.7066500782966614, GAN Loss=0.332949697971344\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 225: Discriminator Loss=0.7062003016471863, GAN Loss=0.3330773711204529\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 226: Discriminator Loss=0.7057713866233826, GAN Loss=0.3331912159919739\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 227: Discriminator Loss=0.7053706645965576, GAN Loss=0.3332878053188324\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 228: Discriminator Loss=0.7049906849861145, GAN Loss=0.33337104320526123\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 229: Discriminator Loss=0.7046369910240173, GAN Loss=0.3334401845932007\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 230: Discriminator Loss=0.7043099999427795, GAN Loss=0.3334932029247284\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 231: Discriminator Loss=0.7040069699287415, GAN Loss=0.3335326910018921\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 232: Discriminator Loss=0.703723132610321, GAN Loss=0.33355712890625\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 233: Discriminator Loss=0.7034643292427063, GAN Loss=0.33356973528862\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 234: Discriminator Loss=0.7032224535942078, GAN Loss=0.333569198846817\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 235: Discriminator Loss=0.7029982805252075, GAN Loss=0.3335590362548828\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 236: Discriminator Loss=0.7027960419654846, GAN Loss=0.33353787660598755\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 237: Discriminator Loss=0.7026015520095825, GAN Loss=0.3335070013999939\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 238: Discriminator Loss=0.7024192810058594, GAN Loss=0.33346936106681824\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 239: Discriminator Loss=0.702247142791748, GAN Loss=0.33342671394348145\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 240: Discriminator Loss=0.702083170413971, GAN Loss=0.33338072896003723\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 241: Discriminator Loss=0.7019180655479431, GAN Loss=0.333331823348999\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 242: Discriminator Loss=0.7017637491226196, GAN Loss=0.3332829475402832\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 243: Discriminator Loss=0.701606273651123, GAN Loss=0.33323729038238525\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 244: Discriminator Loss=0.7014411091804504, GAN Loss=0.33319365978240967\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 245: Discriminator Loss=0.7012720704078674, GAN Loss=0.33315473794937134\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 246: Discriminator Loss=0.7010960578918457, GAN Loss=0.3331219553947449\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 247: Discriminator Loss=0.70091313123703, GAN Loss=0.3330981731414795\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 248: Discriminator Loss=0.7007195353507996, GAN Loss=0.3330797851085663\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 249: Discriminator Loss=0.7002464532852173, GAN Loss=0.3330775499343872\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 250: Discriminator Loss=0.7000697255134583, GAN Loss=0.3330909013748169\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 251: Discriminator Loss=0.6998871564865112, GAN Loss=0.33311712741851807\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 252: Discriminator Loss=0.699691116809845, GAN Loss=0.3331573009490967\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 253: Discriminator Loss=0.6994861960411072, GAN Loss=0.3332080543041229\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 254: Discriminator Loss=0.6992735862731934, GAN Loss=0.33326882123947144\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 255: Discriminator Loss=0.6990486979484558, GAN Loss=0.33333975076675415\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 256: Discriminator Loss=0.6988163590431213, GAN Loss=0.33341896533966064\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 257: Discriminator Loss=0.6985775828361511, GAN Loss=0.3335041105747223\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "Epoch 258: Discriminator Loss=0.6983279585838318, GAN Loss=0.3335949182510376\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 259: Discriminator Loss=0.6980790495872498, GAN Loss=0.33369067311286926\n",
            "1/1 [==============================] - 1s 567ms/step\n",
            "Epoch 260: Discriminator Loss=0.6978242993354797, GAN Loss=0.33378899097442627\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 261: Discriminator Loss=0.697567880153656, GAN Loss=0.33389046788215637\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 262: Discriminator Loss=0.6973071694374084, GAN Loss=0.33399417996406555\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "Epoch 263: Discriminator Loss=0.6970491409301758, GAN Loss=0.3341009318828583\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 264: Discriminator Loss=0.6967922449111938, GAN Loss=0.33420422673225403\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 265: Discriminator Loss=0.6965348124504089, GAN Loss=0.33430925011634827\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 266: Discriminator Loss=0.6962823867797852, GAN Loss=0.3344126343727112\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 267: Discriminator Loss=0.6960330009460449, GAN Loss=0.33451414108276367\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 268: Discriminator Loss=0.6957864761352539, GAN Loss=0.3346126079559326\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 269: Discriminator Loss=0.6955429911613464, GAN Loss=0.3347102999687195\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 270: Discriminator Loss=0.6953030228614807, GAN Loss=0.3348044753074646\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Epoch 271: Discriminator Loss=0.6950704455375671, GAN Loss=0.3348962068557739\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 272: Discriminator Loss=0.6948410272598267, GAN Loss=0.334983229637146\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 273: Discriminator Loss=0.6946219205856323, GAN Loss=0.3350677490234375\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 274: Discriminator Loss=0.6944047212600708, GAN Loss=0.33515051007270813\n",
            "1/1 [==============================] - 1s 592ms/step\n",
            "Epoch 275: Discriminator Loss=0.694190502166748, GAN Loss=0.3352270722389221\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 276: Discriminator Loss=0.6939843893051147, GAN Loss=0.3353014588356018\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 277: Discriminator Loss=0.6937816739082336, GAN Loss=0.33537057042121887\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 278: Discriminator Loss=0.6935856342315674, GAN Loss=0.3354363441467285\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 279: Discriminator Loss=0.6933927536010742, GAN Loss=0.33549895882606506\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 280: Discriminator Loss=0.6932053565979004, GAN Loss=0.33556127548217773\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 281: Discriminator Loss=0.6930187940597534, GAN Loss=0.33561813831329346\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 282: Discriminator Loss=0.6928388476371765, GAN Loss=0.33567214012145996\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 283: Discriminator Loss=0.6926615238189697, GAN Loss=0.33572524785995483\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 284: Discriminator Loss=0.6924893260002136, GAN Loss=0.3357749879360199\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 285: Discriminator Loss=0.692315936088562, GAN Loss=0.3358229100704193\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 286: Discriminator Loss=0.6921448111534119, GAN Loss=0.335870623588562\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 287: Discriminator Loss=0.6919779777526855, GAN Loss=0.3359166383743286\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 288: Discriminator Loss=0.6918115615844727, GAN Loss=0.33595937490463257\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 289: Discriminator Loss=0.691645085811615, GAN Loss=0.33600500226020813\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 290: Discriminator Loss=0.6914804577827454, GAN Loss=0.3360480070114136\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 291: Discriminator Loss=0.6913148760795593, GAN Loss=0.3360935151576996\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 292: Discriminator Loss=0.6911500692367554, GAN Loss=0.33613505959510803\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 293: Discriminator Loss=0.6909863352775574, GAN Loss=0.3361779749393463\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 294: Discriminator Loss=0.690822184085846, GAN Loss=0.33622342348098755\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 295: Discriminator Loss=0.6906556487083435, GAN Loss=0.33626723289489746\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 296: Discriminator Loss=0.6904910206794739, GAN Loss=0.336312860250473\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 297: Discriminator Loss=0.6903263926506042, GAN Loss=0.3363574743270874\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 298: Discriminator Loss=0.6901588439941406, GAN Loss=0.3364024758338928\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 299: Discriminator Loss=0.689993143081665, GAN Loss=0.3364493250846863\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 300: Discriminator Loss=0.6898284554481506, GAN Loss=0.33649584650993347\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 301: Discriminator Loss=0.6896610856056213, GAN Loss=0.3365427851676941\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 302: Discriminator Loss=0.6894937753677368, GAN Loss=0.33658918738365173\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 303: Discriminator Loss=0.6893256902694702, GAN Loss=0.33663344383239746\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 304: Discriminator Loss=0.6891605854034424, GAN Loss=0.3366800546646118\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "Epoch 305: Discriminator Loss=0.6889932751655579, GAN Loss=0.33672407269477844\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 306: Discriminator Loss=0.6888284087181091, GAN Loss=0.3367679715156555\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 307: Discriminator Loss=0.6886640191078186, GAN Loss=0.33681151270866394\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 308: Discriminator Loss=0.6884995698928833, GAN Loss=0.33685293793678284\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 309: Discriminator Loss=0.6883372664451599, GAN Loss=0.3368929326534271\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 310: Discriminator Loss=0.6881767511367798, GAN Loss=0.33693015575408936\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 311: Discriminator Loss=0.6880174279212952, GAN Loss=0.33696669340133667\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 312: Discriminator Loss=0.6878606081008911, GAN Loss=0.33700013160705566\n",
            "1/1 [==============================] - 1s 635ms/step\n",
            "Epoch 313: Discriminator Loss=0.6877068281173706, GAN Loss=0.3370319604873657\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 314: Discriminator Loss=0.6875536441802979, GAN Loss=0.3370603919029236\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 315: Discriminator Loss=0.6874033212661743, GAN Loss=0.3370864987373352\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 316: Discriminator Loss=0.6872581839561462, GAN Loss=0.3371101915836334\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 317: Discriminator Loss=0.6871135830879211, GAN Loss=0.3371295928955078\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 318: Discriminator Loss=0.6869729161262512, GAN Loss=0.3371467590332031\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 319: Discriminator Loss=0.6868351101875305, GAN Loss=0.3371596336364746\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 320: Discriminator Loss=0.6866999268531799, GAN Loss=0.3371703624725342\n",
            "1/1 [==============================] - 1s 605ms/step\n",
            "Epoch 321: Discriminator Loss=0.686570942401886, GAN Loss=0.33717745542526245\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 322: Discriminator Loss=0.686442494392395, GAN Loss=0.33717942237854004\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 323: Discriminator Loss=0.6863193511962891, GAN Loss=0.3371801972389221\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 324: Discriminator Loss=0.6861993670463562, GAN Loss=0.3371773362159729\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 325: Discriminator Loss=0.686082124710083, GAN Loss=0.33717188239097595\n",
            "1/1 [==============================] - 1s 587ms/step\n",
            "Epoch 326: Discriminator Loss=0.6859675645828247, GAN Loss=0.33716246485710144\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 327: Discriminator Loss=0.6858556866645813, GAN Loss=0.3371511399745941\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 328: Discriminator Loss=0.685748279094696, GAN Loss=0.33713674545288086\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 329: Discriminator Loss=0.6856436133384705, GAN Loss=0.3371196389198303\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 330: Discriminator Loss=0.6855419874191284, GAN Loss=0.3370994031429291\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 331: Discriminator Loss=0.6854398846626282, GAN Loss=0.33707791566848755\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "Epoch 332: Discriminator Loss=0.6853430271148682, GAN Loss=0.3370552361011505\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 333: Discriminator Loss=0.6852483749389648, GAN Loss=0.33702948689460754\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 334: Discriminator Loss=0.6851534247398376, GAN Loss=0.337002694606781\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 335: Discriminator Loss=0.6850608587265015, GAN Loss=0.33697471022605896\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 336: Discriminator Loss=0.6849703788757324, GAN Loss=0.3369452953338623\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Epoch 337: Discriminator Loss=0.6848806142807007, GAN Loss=0.33691462874412537\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 338: Discriminator Loss=0.6847915649414062, GAN Loss=0.3368847668170929\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 339: Discriminator Loss=0.684703528881073, GAN Loss=0.336853563785553\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 340: Discriminator Loss=0.6846163868904114, GAN Loss=0.3368217349052429\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 341: Discriminator Loss=0.6845283508300781, GAN Loss=0.33678996562957764\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "Epoch 342: Discriminator Loss=0.6844415068626404, GAN Loss=0.3367578089237213\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Epoch 343: Discriminator Loss=0.6843525767326355, GAN Loss=0.3367273509502411\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 344: Discriminator Loss=0.684264063835144, GAN Loss=0.33669671416282654\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 345: Discriminator Loss=0.6841752529144287, GAN Loss=0.336666464805603\n",
            "1/1 [==============================] - 1s 570ms/step\n",
            "Epoch 346: Discriminator Loss=0.684084951877594, GAN Loss=0.3366379141807556\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 347: Discriminator Loss=0.6839929223060608, GAN Loss=0.3366101384162903\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 348: Discriminator Loss=0.6839022040367126, GAN Loss=0.33658313751220703\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 349: Discriminator Loss=0.6838088035583496, GAN Loss=0.336558073759079\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 350: Discriminator Loss=0.6837136745452881, GAN Loss=0.3365347981452942\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 351: Discriminator Loss=0.6836184859275818, GAN Loss=0.3365122973918915\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 352: Discriminator Loss=0.6835194826126099, GAN Loss=0.3364916443824768\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 353: Discriminator Loss=0.6834185719490051, GAN Loss=0.33647289872169495\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 354: Discriminator Loss=0.6833174824714661, GAN Loss=0.3364565372467041\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 355: Discriminator Loss=0.6832125186920166, GAN Loss=0.33644187450408936\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 356: Discriminator Loss=0.6831064820289612, GAN Loss=0.33642977476119995\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 357: Discriminator Loss=0.6829964518547058, GAN Loss=0.3364197611808777\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 358: Discriminator Loss=0.6828858256340027, GAN Loss=0.33641135692596436\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 359: Discriminator Loss=0.6827717423439026, GAN Loss=0.336405873298645\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "Epoch 360: Discriminator Loss=0.6826543807983398, GAN Loss=0.3364027142524719\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 361: Discriminator Loss=0.6825354099273682, GAN Loss=0.3364025950431824\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 362: Discriminator Loss=0.6824146509170532, GAN Loss=0.33640456199645996\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 363: Discriminator Loss=0.6822888851165771, GAN Loss=0.3364098370075226\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 364: Discriminator Loss=0.682161808013916, GAN Loss=0.3364168703556061\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 365: Discriminator Loss=0.6820327043533325, GAN Loss=0.33642667531967163\n",
            "1/1 [==============================] - 1s 592ms/step\n",
            "Epoch 366: Discriminator Loss=0.6818999648094177, GAN Loss=0.3364388942718506\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 367: Discriminator Loss=0.6817643046379089, GAN Loss=0.33645445108413696\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 368: Discriminator Loss=0.6816254258155823, GAN Loss=0.3364719748497009\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 369: Discriminator Loss=0.6814859509468079, GAN Loss=0.3364926278591156\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 370: Discriminator Loss=0.681341290473938, GAN Loss=0.336516410112381\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 371: Discriminator Loss=0.6811952590942383, GAN Loss=0.3365412652492523\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 372: Discriminator Loss=0.681046187877655, GAN Loss=0.33657020330429077\n",
            "1/1 [==============================] - 1s 605ms/step\n",
            "Epoch 373: Discriminator Loss=0.6808943152427673, GAN Loss=0.3366013467311859\n",
            "1/1 [==============================] - 1s 603ms/step\n",
            "Epoch 374: Discriminator Loss=0.6807401180267334, GAN Loss=0.336635023355484\n",
            "1/1 [==============================] - 1s 611ms/step\n",
            "Epoch 375: Discriminator Loss=0.6805830001831055, GAN Loss=0.3366713225841522\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 376: Discriminator Loss=0.6804236173629761, GAN Loss=0.33671027421951294\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 377: Discriminator Loss=0.6802610754966736, GAN Loss=0.3367517292499542\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 378: Discriminator Loss=0.6800973415374756, GAN Loss=0.33679497241973877\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 379: Discriminator Loss=0.679930567741394, GAN Loss=0.336841344833374\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 380: Discriminator Loss=0.6797598600387573, GAN Loss=0.33689016103744507\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "Epoch 381: Discriminator Loss=0.6795886158943176, GAN Loss=0.3369414508342743\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 382: Discriminator Loss=0.6794149875640869, GAN Loss=0.3369944095611572\n",
            "1/1 [==============================] - 1s 598ms/step\n",
            "Epoch 383: Discriminator Loss=0.6792378425598145, GAN Loss=0.33705008029937744\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 384: Discriminator Loss=0.6790602207183838, GAN Loss=0.3371081054210663\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 385: Discriminator Loss=0.6788792014122009, GAN Loss=0.33716803789138794\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 386: Discriminator Loss=0.6786964535713196, GAN Loss=0.33723005652427673\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 387: Discriminator Loss=0.6785122752189636, GAN Loss=0.33729416131973267\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 388: Discriminator Loss=0.678325355052948, GAN Loss=0.33736005425453186\n",
            "1/1 [==============================] - 1s 578ms/step\n",
            "Epoch 389: Discriminator Loss=0.6781370043754578, GAN Loss=0.33742859959602356\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 390: Discriminator Loss=0.6779459714889526, GAN Loss=0.3374982178211212\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "Epoch 391: Discriminator Loss=0.6777549386024475, GAN Loss=0.3375706076622009\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 392: Discriminator Loss=0.6775603294372559, GAN Loss=0.3376438617706299\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 393: Discriminator Loss=0.6773653030395508, GAN Loss=0.3377198278903961\n",
            "1/1 [==============================] - 1s 592ms/step\n",
            "Epoch 394: Discriminator Loss=0.6771675944328308, GAN Loss=0.337796688079834\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 395: Discriminator Loss=0.6769695281982422, GAN Loss=0.33787548542022705\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 396: Discriminator Loss=0.6767695546150208, GAN Loss=0.3379563093185425\n",
            "1/1 [==============================] - 1s 593ms/step\n",
            "Epoch 397: Discriminator Loss=0.6765680313110352, GAN Loss=0.3380381464958191\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 398: Discriminator Loss=0.6763644814491272, GAN Loss=0.3381223678588867\n",
            "1/1 [==============================] - 1s 621ms/step\n",
            "Epoch 399: Discriminator Loss=0.6761597990989685, GAN Loss=0.3382071852684021\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 400: Discriminator Loss=0.6759545207023621, GAN Loss=0.3382938504219055\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 401: Discriminator Loss=0.6757476925849915, GAN Loss=0.3383822441101074\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 402: Discriminator Loss=0.6755391955375671, GAN Loss=0.33847081661224365\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "Epoch 403: Discriminator Loss=0.675330400466919, GAN Loss=0.33856210112571716\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 404: Discriminator Loss=0.6751195192337036, GAN Loss=0.3386543095111847\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 405: Discriminator Loss=0.6749083399772644, GAN Loss=0.3387472331523895\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 406: Discriminator Loss=0.6746951937675476, GAN Loss=0.3388417065143585\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "Epoch 407: Discriminator Loss=0.6744819283485413, GAN Loss=0.3389371633529663\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 408: Discriminator Loss=0.674267590045929, GAN Loss=0.33903446793556213\n",
            "1/1 [==============================] - 1s 587ms/step\n",
            "Epoch 409: Discriminator Loss=0.6740511059761047, GAN Loss=0.33913254737854004\n",
            "1/1 [==============================] - 1s 593ms/step\n",
            "Epoch 410: Discriminator Loss=0.6738348603248596, GAN Loss=0.3392314314842224\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "Epoch 411: Discriminator Loss=0.6736177802085876, GAN Loss=0.33933180570602417\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "Epoch 412: Discriminator Loss=0.6733993291854858, GAN Loss=0.3394331932067871\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 413: Discriminator Loss=0.6731799840927124, GAN Loss=0.3395353853702545\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 414: Discriminator Loss=0.6729598045349121, GAN Loss=0.3396390378475189\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 415: Discriminator Loss=0.6727395057678223, GAN Loss=0.3397429287433624\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 416: Discriminator Loss=0.6725179553031921, GAN Loss=0.3398478925228119\n",
            "1/1 [==============================] - 1s 587ms/step\n",
            "Epoch 417: Discriminator Loss=0.6722955703735352, GAN Loss=0.3399542570114136\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Epoch 418: Discriminator Loss=0.6720730662345886, GAN Loss=0.3400617241859436\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 419: Discriminator Loss=0.6718502640724182, GAN Loss=0.3401693105697632\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 420: Discriminator Loss=0.6716287732124329, GAN Loss=0.3402782678604126\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "Epoch 421: Discriminator Loss=0.6714093685150146, GAN Loss=0.3403889536857605\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 422: Discriminator Loss=0.6711788177490234, GAN Loss=0.3405001759529114\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 423: Discriminator Loss=0.6709529757499695, GAN Loss=0.34061264991760254\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 424: Discriminator Loss=0.6707272529602051, GAN Loss=0.3407250642776489\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 425: Discriminator Loss=0.6705020070075989, GAN Loss=0.34083840250968933\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 426: Discriminator Loss=0.6702759861946106, GAN Loss=0.3409525156021118\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 427: Discriminator Loss=0.670049250125885, GAN Loss=0.3410673141479492\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 428: Discriminator Loss=0.6698217988014221, GAN Loss=0.34118273854255676\n",
            "1/1 [==============================] - 1s 587ms/step\n",
            "Epoch 429: Discriminator Loss=0.6695944666862488, GAN Loss=0.3412990868091583\n",
            "1/1 [==============================] - 1s 573ms/step\n",
            "Epoch 430: Discriminator Loss=0.6693671345710754, GAN Loss=0.34141603112220764\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 431: Discriminator Loss=0.6691376566886902, GAN Loss=0.34153276681900024\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 432: Discriminator Loss=0.6689081788063049, GAN Loss=0.34165075421333313\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 433: Discriminator Loss=0.6686789989471436, GAN Loss=0.3417695164680481\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 434: Discriminator Loss=0.668449878692627, GAN Loss=0.341888427734375\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 435: Discriminator Loss=0.6682202219963074, GAN Loss=0.34200817346572876\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "Epoch 436: Discriminator Loss=0.6679897308349609, GAN Loss=0.3421283960342407\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 437: Discriminator Loss=0.6677595376968384, GAN Loss=0.34224921464920044\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "Epoch 438: Discriminator Loss=0.6675285696983337, GAN Loss=0.3423709273338318\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 439: Discriminator Loss=0.6672993302345276, GAN Loss=0.34249281883239746\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 440: Discriminator Loss=0.6670697927474976, GAN Loss=0.3426157236099243\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 441: Discriminator Loss=0.6668380498886108, GAN Loss=0.3427393436431885\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 442: Discriminator Loss=0.6666053533554077, GAN Loss=0.3428633213043213\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 443: Discriminator Loss=0.6663735508918762, GAN Loss=0.34298771619796753\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 444: Discriminator Loss=0.6661412119865417, GAN Loss=0.3431127071380615\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 445: Discriminator Loss=0.6659095883369446, GAN Loss=0.3432379961013794\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 446: Discriminator Loss=0.6656776070594788, GAN Loss=0.343363881111145\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 447: Discriminator Loss=0.6654462814331055, GAN Loss=0.34349024295806885\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 448: Discriminator Loss=0.6652135252952576, GAN Loss=0.34361690282821655\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 449: Discriminator Loss=0.6649815440177917, GAN Loss=0.343744158744812\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 450: Discriminator Loss=0.6647495627403259, GAN Loss=0.3438716232776642\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 451: Discriminator Loss=0.6645167469978333, GAN Loss=0.3439992666244507\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 452: Discriminator Loss=0.6642842888832092, GAN Loss=0.3441275358200073\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 453: Discriminator Loss=0.66405189037323, GAN Loss=0.3442559838294983\n",
            "1/1 [==============================] - 1s 583ms/step\n",
            "Epoch 454: Discriminator Loss=0.6638197898864746, GAN Loss=0.344385027885437\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 455: Discriminator Loss=0.6635879874229431, GAN Loss=0.3445145785808563\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 456: Discriminator Loss=0.6633552312850952, GAN Loss=0.34464412927627563\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 457: Discriminator Loss=0.6631226539611816, GAN Loss=0.34477442502975464\n",
            "1/1 [==============================] - 1s 587ms/step\n",
            "Epoch 458: Discriminator Loss=0.6628909111022949, GAN Loss=0.34490492939949036\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 459: Discriminator Loss=0.6626578569412231, GAN Loss=0.3450356125831604\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "Epoch 460: Discriminator Loss=0.6624255180358887, GAN Loss=0.3451666533946991\n",
            "1/1 [==============================] - 1s 581ms/step\n",
            "Epoch 461: Discriminator Loss=0.6621931791305542, GAN Loss=0.3452979326248169\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 462: Discriminator Loss=0.6619608998298645, GAN Loss=0.3454296886920929\n",
            "1/1 [==============================] - 1s 596ms/step\n",
            "Epoch 463: Discriminator Loss=0.6617287993431091, GAN Loss=0.34556150436401367\n",
            "1/1 [==============================] - 1s 609ms/step\n",
            "Epoch 464: Discriminator Loss=0.6614968180656433, GAN Loss=0.34569403529167175\n",
            "1/1 [==============================] - 1s 593ms/step\n",
            "Epoch 465: Discriminator Loss=0.6612650156021118, GAN Loss=0.34582629799842834\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 466: Discriminator Loss=0.6610330939292908, GAN Loss=0.3459585905075073\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 467: Discriminator Loss=0.660801351070404, GAN Loss=0.34609144926071167\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 468: Discriminator Loss=0.6605697870254517, GAN Loss=0.346224308013916\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 469: Discriminator Loss=0.6603386402130127, GAN Loss=0.3463574945926666\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "Epoch 470: Discriminator Loss=0.6601078510284424, GAN Loss=0.34649085998535156\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "Epoch 471: Discriminator Loss=0.6598763465881348, GAN Loss=0.3466241657733917\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "Epoch 472: Discriminator Loss=0.6596455574035645, GAN Loss=0.3467581868171692\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 473: Discriminator Loss=0.6594147086143494, GAN Loss=0.3468915820121765\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 474: Discriminator Loss=0.6591846346855164, GAN Loss=0.34702569246292114\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 475: Discriminator Loss=0.6589543223381042, GAN Loss=0.34715962409973145\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 476: Discriminator Loss=0.658724844455719, GAN Loss=0.3472937345504761\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 477: Discriminator Loss=0.6584945917129517, GAN Loss=0.34742802381515503\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 478: Discriminator Loss=0.6582647562026978, GAN Loss=0.3475622236728668\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 479: Discriminator Loss=0.6580355763435364, GAN Loss=0.34769678115844727\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "Epoch 480: Discriminator Loss=0.6578064560890198, GAN Loss=0.3478310704231262\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "Epoch 481: Discriminator Loss=0.6575772166252136, GAN Loss=0.34796586632728577\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 482: Discriminator Loss=0.6573488712310791, GAN Loss=0.3481001853942871\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 483: Discriminator Loss=0.6571202874183655, GAN Loss=0.3482348918914795\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "Epoch 484: Discriminator Loss=0.6568921208381653, GAN Loss=0.3483693301677704\n",
            "1/1 [==============================] - 1s 597ms/step\n",
            "Epoch 485: Discriminator Loss=0.6566640734672546, GAN Loss=0.3485041558742523\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "Epoch 486: Discriminator Loss=0.6564369201660156, GAN Loss=0.3486388325691223\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 487: Discriminator Loss=0.6562095880508423, GAN Loss=0.348773330450058\n",
            "1/1 [==============================] - 1s 582ms/step\n",
            "Epoch 488: Discriminator Loss=0.6559827923774719, GAN Loss=0.34890806674957275\n",
            "1/1 [==============================] - 1s 594ms/step\n",
            "Epoch 489: Discriminator Loss=0.6557556986808777, GAN Loss=0.3490423858165741\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "Epoch 490: Discriminator Loss=0.6555293798446655, GAN Loss=0.3491770029067993\n",
            "1/1 [==============================] - 1s 593ms/step\n",
            "Epoch 491: Discriminator Loss=0.6553032994270325, GAN Loss=0.34931135177612305\n",
            "1/1 [==============================] - 1s 609ms/step\n",
            "Epoch 492: Discriminator Loss=0.6550775170326233, GAN Loss=0.34944596886634827\n",
            "1/1 [==============================] - 1s 620ms/step\n",
            "Epoch 493: Discriminator Loss=0.6548515558242798, GAN Loss=0.3495803475379944\n",
            "1/1 [==============================] - 1s 617ms/step\n",
            "Epoch 494: Discriminator Loss=0.6546266078948975, GAN Loss=0.34971457719802856\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 495: Discriminator Loss=0.6544014811515808, GAN Loss=0.3498489260673523\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 496: Discriminator Loss=0.6541771292686462, GAN Loss=0.3499828279018402\n",
            "1/1 [==============================] - 1s 594ms/step\n",
            "Epoch 497: Discriminator Loss=0.6539528965950012, GAN Loss=0.3501169681549072\n",
            "1/1 [==============================] - 1s 600ms/step\n",
            "Epoch 498: Discriminator Loss=0.6537290811538696, GAN Loss=0.35025089979171753\n",
            "1/1 [==============================] - 1s 593ms/step\n",
            "Epoch 499: Discriminator Loss=0.6535055041313171, GAN Loss=0.3503846526145935\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "Epoch 500: Discriminator Loss=0.6532821655273438, GAN Loss=0.3505186140537262\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(0, len(real_data), batch_size):\n",
        "        real_batch = real_data[batch:batch+batch_size]\n",
        "        real_batch = np.expand_dims(real_batch, axis=2)\n",
        "        real_batch = np.repeat(real_batch, vocab_size, axis=2)  # Adjust the third dimension to match fake_data\n",
        "        real_labels = np.ones((len(real_batch), 1))\n",
        "\n",
        "        # Generate fake data using the Generator model\n",
        "        noise = np.random.randint(0, vocab_size, size=(len(real_batch), max_sequence_length-1))\n",
        "        fake_batch = generator_model.predict(noise)\n",
        "        fake_batch = fake_batch[:, :max_sequence_length-1, :]\n",
        "        fake_labels = np.zeros((len(fake_batch), 1))\n",
        "\n",
        "        # Adjust the size of real_batch\n",
        "        real_batch = real_batch[:, :max_sequence_length-1, :]\n",
        "\n",
        "        # Reshape the fake_batch to match the dimensions of real_batch\n",
        "        fake_batch = np.squeeze(fake_batch)\n",
        "\n",
        "        # Combine real and fake data\n",
        "        combined_data = np.concatenate((real_batch, fake_batch[:-1, :]), axis=0)\n",
        "        combined_labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
        "\n",
        "        # Shuffle the combined data and labels\n",
        "        # combined_data, combined_labels = shuffle(combined_data, combined_labels)\n",
        "\n",
        "        # Train the Discriminator\n",
        "        num_samples = combined_data.shape[0]\n",
        "        if batch_size > num_samples:\n",
        "            indices = np.arange(num_samples)\n",
        "        else:\n",
        "            indices = np.random.choice(num_samples, batch_size, replace=False)\n",
        "        discriminator_loss = discriminator_model.train_on_batch(combined_data[indices], combined_labels[indices])\n",
        "\n",
        "        # Train the Generator (via GAN)\n",
        "        gan_noise = np.random.randint(0, vocab_size, size=(batch_size, max_sequence_length-1))\n",
        "        gan_labels = np.ones((batch_size, 1))\n",
        "        gan_loss = gan_model.train_on_batch(gan_noise, gan_labels)\n",
        "\n",
        "    # Print the loss for each epoch\n",
        "    print(f\"Epoch {epoch+1}: Discriminator Loss={discriminator_loss}, GAN Loss={gan_loss}\")\n",
        "    # print(f\"Epoch {epoch+1}: Discriminator Loss={discriminator_loss}\")\n",
        "    # Save the Generator model\n",
        "    # Define the optimizer and loss function\n",
        "    optimizer = Adam()\n",
        "    loss_function = \"binary_crossentropy\"\n",
        "\n",
        "    # Compile the Generator model\n",
        "    generator_model.compile(optimizer=optimizer, loss=loss_function)\n",
        "\n",
        "    # Save the compiled Generator model\n",
        "    generator_model.save(os.path.join(save_dir, \"generator_model_compiled.h5\"))\n",
        "\n",
        "    tokenizer_data = {\n",
        "        'tokenizer': tokenizer,\n",
        "        'max_sequence_length': max_sequence_length\n",
        "    }\n",
        "\n",
        "    # Save the Tokenizer\n",
        "    with open(os.path.join(save_dir, \"tokenizer.pkl\"), \"wb\") as tokenizer_file:\n",
        "        pickle.dump(tokenizer_data, tokenizer_file)\n",
        "\n",
        "    \n",
        "    # Update TensorBoard metrics after each epoch\n",
        "    # tensorboard_callback.on_epoch_end(epoch, logs={'discriminator_loss': discriminator_loss, 'gan_loss': gan_loss})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-k4Mjhu5iKrt"
      },
      "outputs": [],
      "source": [
        "# # Start the TensorBoard server\n",
        "# tensorboard.program.TensorBoard(\n",
        "#     logdir=log_dir,\n",
        "#     host=\"localhost\",\n",
        "#     port=6006,\n",
        "#     reload_interval=5  # Refresh the TensorBoard server every 5 seconds\n",
        "# ).main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "koUTanqi7LKI"
      },
      "outputs": [],
      "source": [
        "def preprocess_input(user_input):\n",
        "    # Tokenize the user input\n",
        "    tokens = user_input.strip().split()\n",
        "\n",
        "    # Convert tokens to lowercase\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "\n",
        "    # Perform any additional preprocessing steps\n",
        "    # ...\n",
        "\n",
        "    # Return the preprocessed input\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def generate_response(input_tokens, generator_model):\n",
        "    # Convert input tokens to numerical representation\n",
        "    input_sequence = tokenizer.texts_to_sequences([input_tokens])\n",
        "    input_sequence = pad_sequences(input_sequence, maxlen=max_sequence_length-1)\n",
        "    # Generate response using the generator model\n",
        "    print('input sequence :',input_sequence)\n",
        "    generated_sequence = generator_model.predict(input_sequence)\n",
        "    print('generated_sequence :',generated_sequence)\n",
        "\n",
        "    # Convert numerical representation back to tokens\n",
        "    # generated_tokens = tokenizer.sequences_to_texts(generated_sequence)[0].split()\n",
        "\n",
        "    generated_tokens = [tokenizer.index_word.get(index, \"\") for index in np.argmax(generated_sequence, axis=-1)[0]]\n",
        "    generated_tokens = [token for token in generated_tokens if token]\n",
        "\n",
        "    # print('generated_sequence function:',generated_tokens)\n",
        "\n",
        "    # Return the generated response tokens\n",
        "    return generated_tokens\n",
        "\n",
        "\n",
        "def postprocess_response(response_tokens):\n",
        "    # Convert tokens to string\n",
        "    response_text = ' '.join(response_tokens)\n",
        "\n",
        "    # Perform any postprocessing steps, such as capitalization or punctuation handling\n",
        "    # ...\n",
        "\n",
        "    # Return the postprocessed response\n",
        "    return response_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BGuruuWQHgKf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input sequence : [[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 95 23]]\n",
            "1/1 [==============================] - 1s 531ms/step\n",
            "generated_sequence : [[[1.47752115e-03 2.01081578e-03 1.67330517e-03 ... 1.47211889e-03\n",
            "   1.15661428e-03 1.70213044e-01]\n",
            "  [1.47906409e-04 2.67772819e-04 2.05254604e-04 ... 1.60474956e-04\n",
            "   9.81829435e-05 3.96102250e-01]\n",
            "  [6.44641041e-05 1.28536019e-04 9.71476911e-05 ... 7.33205743e-05\n",
            "   4.07888147e-05 4.35839206e-01]\n",
            "  ...\n",
            "  [5.06466131e-05 1.04158818e-04 7.84786243e-05 ... 5.87083596e-05\n",
            "   3.16432815e-05 4.44969505e-01]\n",
            "  [5.06469405e-05 1.04159495e-04 7.84791264e-05 ... 5.87087961e-05\n",
            "   3.16435180e-05 4.44968998e-01]\n",
            "  [5.06463693e-05 1.04158426e-04 7.84783988e-05 ... 5.87081886e-05\n",
            "   3.16430996e-05 4.44969505e-01]]]\n",
            "generated response ['sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet', 'sweet']\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    # Preprocess user input\n",
        "    processed_input = preprocess_input(user_input)\n",
        "\n",
        "    # Generate response using the generator model\n",
        "    generated_response = generate_response(processed_input, generator_model)\n",
        "    print('generated response',generated_response)\n",
        "\n",
        "    # Postprocess and display the generated response\n",
        "    response = postprocess_response(generated_response)\n",
        "    # print(\"Chatbot: \" + response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
